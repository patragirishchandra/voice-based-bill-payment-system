{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c915c8b-8e32-4870-bdaf-aa6118a70f96",
   "metadata": {},
   "source": [
    "# Testing out Local LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d25a7e3-d464-477f-9c07-417f6fd62be7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_ollama'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_ollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOllama\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tool\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AIMessage, HumanMessage, SystemMessage\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_ollama'"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a12c69f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ebef53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "844092bb-1bd2-4037-baaf-5ed9f413838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "# llm = ChatOllama(model=\"llama3.2:1b\", temperature=0)\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d955cf4-be35-4075-b37d-3ea3c2772731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"To proceed with paying your bill, I need to know a few details first.\\n\\nCan you please tell me the number of the bill you'd like to pay?\", additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-12T22:14:36.447587Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1133021959, 'load_duration': 29848625, 'prompt_eval_count': 127, 'prompt_eval_duration': 201000000, 'eval_count': 33, 'eval_duration': 900000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-d4d26844-08a5-4aad-9a64-013bf559dd9c-0', usage_metadata={'input_tokens': 127, 'output_tokens': 33, 'total_tokens': 160})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialSystemMessage = '''You are an excellent virtual assistant to help with payment of bills.\n",
    "You should follow the following steps strictly to pay the bills:\n",
    "1. Ask the user the bill number\n",
    "2. Ask the user if you should fetch the bill details.\n",
    "3. Inform the user the bill details once fetched.\n",
    "4. Ask the user if you should pay the bill.\n",
    "5. Is the user agrees, pay the bill.\n",
    "\n",
    "You should never user external knowledge, assumptions or information beyond what is explicitly shared or recieved.\n",
    "'''\n",
    "\n",
    "\n",
    "messages = [\n",
    "    (\"system\",initialSystemMessage),\n",
    "    (\"human\", \"Pay my bill\")\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce8425-ee02-4c78-afb8-e0a206f795fe",
   "metadata": {},
   "source": [
    "## Testing Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae52d71-5e10-4665-9499-9f2f21833d05",
   "metadata": {},
   "source": [
    "### Calculator Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1556dfef-a5f2-4ef0-afde-693a75ff0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add (+) two numbers\"\"\"\n",
    "    return a+b\n",
    "    \n",
    "@tool\n",
    "def sub(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract (-) two numbers\"\"\"\n",
    "    return a-b\n",
    "    \n",
    "@tool\n",
    "def mul(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply (*, x) two numbers\"\"\"\n",
    "    return a*b\n",
    "    \n",
    "@tool\n",
    "def div(a: int, b: int) -> int:\n",
    "    \"\"\"Divide (/) two numbers\"\"\"\n",
    "    return a/b\n",
    "\n",
    "@tool\n",
    "def fetchUserDets(name: str) -> str:\n",
    "    \"\"\"Function to fetch user details. Input is name of the user. Output relevant details.\"\"\"\n",
    "    # hmap = \n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "tools = [mul, div, add, sub]\n",
    "toolsMap = {'add':add, \"sub\":sub, \"mul\":mul, \"div\":div}\n",
    "\n",
    "llmTools = llm.bind_tools(tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0cdbb0-94b7-4241-a71f-996319510ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c77b6c9a-6435-468e-b793-1e7b0f703e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-09T22:54:25.2212492Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2882431800, 'load_duration': 53992000, 'prompt_eval_count': 353, 'prompt_eval_duration': 23000000, 'eval_count': 44, 'eval_duration': 2799000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-c5d7bdb8-835e-4270-ae67-f75cf434ef9a-0', tool_calls=[{'name': 'mul', 'args': {'a': 3, 'b': 12}, 'id': 'f1203f1f-0351-4a91-830b-16f2f5f301be', 'type': 'tool_call'}, {'name': 'sub', 'args': {'a': 11, 'b': 49}, 'id': '7fb06331-ac6d-4474-8cb6-b2c66d70bfb7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 353, 'output_tokens': 44, 'total_tokens': 397})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Add 3 and 4?\"\n",
    "query = \"What is 3 multiplied 12? Also, what is 11 + 49?\"\n",
    "\n",
    "# llmTools.invoke(query).tool_calls\n",
    "\n",
    "messages = [\n",
    "    (\"system\",\"You are a helpful assistant. be kind\"),\n",
    "    (\"human\", \"Tell me the answer to 3 * 12? Also, what is 11 - 49?\")\n",
    "]\n",
    "ai_msg = llmTools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b2d74fa-2cd2-480f-8b64-107c5b25dcd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'mul',\n",
       "  'args': {'a': 3, 'b': 12},\n",
       "  'id': 'f1203f1f-0351-4a91-830b-16f2f5f301be',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'sub',\n",
       "  'args': {'a': 11, 'b': 49},\n",
       "  'id': '7fb06331-ac6d-4474-8cb6-b2c66d70bfb7',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75446aba-e14a-4498-88fe-100b5ed65215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('system', 'You are a helpful assistant. be kind'),\n",
       " ('human', 'Tell me the answer to 3 * 12? Also, what is 11 - 49?'),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-09T22:54:25.2212492Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2882431800, 'load_duration': 53992000, 'prompt_eval_count': 353, 'prompt_eval_duration': 23000000, 'eval_count': 44, 'eval_duration': 2799000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-c5d7bdb8-835e-4270-ae67-f75cf434ef9a-0', tool_calls=[{'name': 'mul', 'args': {'a': 3, 'b': 12}, 'id': 'f1203f1f-0351-4a91-830b-16f2f5f301be', 'type': 'tool_call'}, {'name': 'sub', 'args': {'a': 11, 'b': 49}, 'id': '7fb06331-ac6d-4474-8cb6-b2c66d70bfb7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 353, 'output_tokens': 44, 'total_tokens': 397})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0e11b63-9d16-4ad8-9c9c-17f4e1893d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('system', 'You are a helpful assistant. be kind'),\n",
       " ('human', 'Tell me the answer to 3 * 12? Also, what is 11 - 49?'),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-09T22:54:25.2212492Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2882431800, 'load_duration': 53992000, 'prompt_eval_count': 353, 'prompt_eval_duration': 23000000, 'eval_count': 44, 'eval_duration': 2799000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-c5d7bdb8-835e-4270-ae67-f75cf434ef9a-0', tool_calls=[{'name': 'mul', 'args': {'a': 3, 'b': 12}, 'id': 'f1203f1f-0351-4a91-830b-16f2f5f301be', 'type': 'tool_call'}, {'name': 'sub', 'args': {'a': 11, 'b': 49}, 'id': '7fb06331-ac6d-4474-8cb6-b2c66d70bfb7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 353, 'output_tokens': 44, 'total_tokens': 397}),\n",
       " ToolMessage(content='36', name='mul', tool_call_id='f1203f1f-0351-4a91-830b-16f2f5f301be'),\n",
       " ToolMessage(content='-38', name='sub', tool_call_id='7fb06331-ac6d-4474-8cb6-b2c66d70bfb7')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for toolCall in ai_msg.tool_calls:\n",
    "    toolSelected = toolsMap[toolCall['name']]\n",
    "    toolMsg = toolSelected.invoke(toolCall)\n",
    "    messages.append(toolMsg)\n",
    "    \n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17aa6318-8cc8-4256-9683-81acf6dc2b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_msg = llmTools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5513aaf5-cfbf-4ee0-b14a-a9d21318949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to 3 * 12 is 36.\n",
      "\n",
      "The answer to 11 - 49 is -38.\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc85ddc1-4f89-4a8d-b8d4-a35f39677769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The answer to 3 * 12 is 36.\\n\\nThe answer to 11 - 49 is -38.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-09T22:54:26.2939606Z', 'done': True, 'done_reason': 'stop', 'total_duration': 981457900, 'load_duration': 57474600, 'prompt_eval_count': 137, 'prompt_eval_duration': 10000000, 'eval_count': 25, 'eval_duration': 907000000, 'message': Message(role='assistant', content='The answer to 3 * 12 is 36.\\n\\nThe answer to 11 - 49 is -38.', images=None, tool_calls=None)}, id='run-194d59fa-b28f-4ec4-9bf4-00d648665da4-0', usage_metadata={'input_tokens': 137, 'output_tokens': 25, 'total_tokens': 162})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afd6eab1-dcee-4fbf-996f-79c503343156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to 3 * 12 is 36.\n",
      "\n",
      "The answer to 11 - 49 is -38.\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a504f-7695-474c-9308-63e2d730b7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "802134be-f20a-4a53-96e7-9799f1b4e651",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "647913ff-0048-4abe-a09c-62b4324f980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/asutoshdalei/Desktop/Work/solar/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab406fb-7e75-494c-9fe6-552889547294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/asutoshdalei/Desktop/Work/solar/bin/python3.11'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5035250f-d11e-4f17-86ce-350092a78728",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialSystemMessage = '''You are an excellent virtual assistant to help with payment of bills.\n",
    "You should follow the following steps strictly to pay the bills:\n",
    "1. Ask the user the bill number\n",
    "2. Ask the user if you should fetch the bill details.\n",
    "3. Inform the user the bill details once fetched.\n",
    "4. Ask the user if you should pay the bill.\n",
    "5. Is the user agrees, pay the bill.\n",
    "\n",
    "You should never user external knowledge, assumptions or information beyond what is explicitly shared or recieved.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11eeaef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an excellent virtual assistant to help with payment of bills.\n",
      "You should follow the following steps strictly to pay the bills:\n",
      "1. Ask the user the bill number\n",
      "2. Ask the user if you should fetch the bill details.\n",
      "3. Inform the user the bill details once fetched.\n",
      "4. Ask the user if you should pay the bill.\n",
      "5. Is the user agrees, pay the bill.\n",
      "\n",
      "You should never user external knowledge, assumptions or information beyond what is explicitly shared or recieved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(initialSystemMessage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43165f9",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8294574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# Importing model\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46bf1df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "billDB = {\n",
    "    9182:{'Customer Name':'Asutosh Dalei','service provider':'TS Elec Board','unit':32,'Amount':341, \"Due Date\":'10/01/2025', 'status':'Paid'},\n",
    "    1928:{'Customer Name':'Asutosh Dalei','service provider':'TS Elec Board','unit':37,'Amount':547, \"Due Date\":'11/02/2025','status':'Unpaid'},\n",
    "    1038:{'Customer Name':'Asutosh Dalei','service provider':'TS Elec Board','unit':23,'Amount':298, \"Due Date\":'09/10/2025','status':'Paid'}\n",
    "}\n",
    "\n",
    "\n",
    "initialSystemMessage = '''You are an excellent virtual assistant. Your name is PayLLM. In the first user interaction, respond directly without calling any tools.\n",
    "You should strictly follow the following steps:\n",
    "0. Ask the user if they want to pay any bill.\n",
    "1. Ask the user the bill number.\n",
    "2. Ask the user if you should fetch the bill details.\n",
    "3. Inform the user the bill details once fetched.\n",
    "4. Ask the user if you should pay the bill.\n",
    "5. Is the user agrees, pay the bill.\n",
    "\n",
    "You should never use external knowledge, assumptions or information beyond what is explicitly shared or recieved.\n",
    "Strictly do not call tools unless absolutely needed.\n",
    "\n",
    "Example:\n",
    "User: Hello\n",
    "PayLLM: Hi. To help with your payments, please provide your bill number.\n",
    "User: 12345.\n",
    "PayLLM: Sure, should I fetch the bill?\n",
    "User: Yes, sure.\n",
    "PayLLM: The bill amount is 145\n",
    "User: Okay. Go ahead and pay it.\n",
    "PayLLM: Sure.\n",
    "PayLLM: The bill is paid.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13710f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def payBill(billNumber: str) -> str:\n",
    "    \"\"\"Function to pay bill using bill number.\n",
    "    Args:\n",
    "        billNumber: Bill Number (String). Output: Bill paid status\n",
    "    \"\"\"\n",
    "    print(billNumber, type(billNumber))\n",
    "    if billDB[billNumber]['status'] == 'Paid':\n",
    "        return \"Bill paid already\"\n",
    "    billDB[billNumber]['status'] = 'Paid'\n",
    "    return \"Bill paid successfully\"\n",
    "\n",
    "serviceTools = [payBill]\n",
    "serviceToolsMap = {\"payBill\": payBill}\n",
    "\n",
    "firstInteraction = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5713966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event(llm):\n",
    "    serviceMessages = [SystemMessage(content = initialSystemMessage), HumanMessage(content='Help me pay my bill. Ask me my bill number.')]\n",
    "    llmService = llm\n",
    "    aiMsgSer = llmService.invoke(serviceMessages)\n",
    "    while True:\n",
    "        if firstInteraction:\n",
    "                print(f\"AI Response:\\n --> {aiMsgSer.content}\")\n",
    "                firstInteraction = False\n",
    "                llmService = llm.bind_tools(serviceTools)\n",
    "\n",
    "        if aiMsgSer.tool_calls:\n",
    "            for toolCallSer in aiMsgSer.tool_calls:\n",
    "\n",
    "                toolSelected = serviceToolsMap[toolCallSer['name']]\n",
    "                toolMsg = toolSelected.invoke(toolCallSer)\n",
    "                print(toolMsg)\n",
    "                serviceMessages.append(toolMsg)\n",
    "\n",
    "\n",
    "            aiMsgSer = llmService.invoke(serviceMessages)\n",
    "            serviceMessages.append(aiMsgSer)\n",
    "            print(f\"AI Response:\\n --> {aiMsgSer.content}\")\n",
    "            continue\n",
    "        userInput = input(\"User Input:\\n -->\")\n",
    "        if userInput == \"/end\":\n",
    "            break\n",
    "        serviceMessages.append(HumanMessage(content = userInput))\n",
    "        aiMsgSer = llmService.invoke(serviceMessages)\n",
    "        if aiMsgSer.content != '':\n",
    "            print(f\"AI Response:\\n--> {aiMsgSer.content}\")\n",
    "        serviceMessages.append(HumanMessage(content = userInput))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e4fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot access local variable 'llmService' where it is not associated with a value\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    event()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc486f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lunar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
